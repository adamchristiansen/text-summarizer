"""
This module provides methods for loading and manipulating JSON documents
generated by the programs.
"""

import functools
import json
import operator

from utils import text

class Document:
    """
    Represents a document as a sequence of sentences.
    """

    def __init__(self, orig_article=None, orig_summary=None,
            sent_gen_summary=None, sent_orig_article=None,
            sent_orig_summary=None, title=None, topic=None):
        """
        Create an object consisting of the components of a document.

        # Arguments

        * `orig_article` (str): The original article.
        * `orig_summary` (str): The original summary.
        * `sent_gen_summary` (list<str>): The sentences in the generated
            summary.
        * `sent_orig_article` (list<str>): The sentences in the original
            article.
        * `sent_orig_summary` (list<str>): The sentences in the original
            summary.
        * `title` (str): The title of the article.
        * `topic` (str): The topic of the article.
        """
        self.orig_article      = orig_article
        self.orig_summary      = orig_summary
        self.sent_gen_summary  = sent_gen_summary
        self.sent_orig_article = sent_orig_article
        self.sent_orig_summary = sent_orig_summary
        self.title             = title
        self.topic             = topic

    @staticmethod
    def load_file(path):
        """
        Load a JSON document from a file.

        # Arguments

        * `path` (str): The path to the file.

        # Returns

        (Document): A document created using the specified JSON file.
        """
        with open(path) as f:
            return Document(**json.load(f))

    def dump_file(self, path):
        """
        Serialize as a JSON object.

        # Arguments

        * `path` (str): The path to the file to dump the JSON.
        """
        data = {
            'orig_article':      self.orig_article,
            'orig_summary':      self.orig_summary,
            'sent_gen_summary':  self.sent_gen_summary,
            'sent_orig_article': self.sent_orig_article,
            'sent_orig_summary': self.sent_orig_summary,
            'title':             self.title,
            'topic':             self.topic,
        }
        with open(path, 'w') as f:
            json.dump(data, f, indent=2, sort_keys=True)

    def article_clean_word_sentences(self):
        """
        Clean the sentences in the article by breaking them into words and
        removing punctuation.

        # Returns

        (list<list<str>>): A list of sentences, where each sentence is a list
            of words.
        """
        cleaned = []
        for sentence in self.sent_orig_article:
            cleaned.append(text.split_words(sentence))
        return cleaned

    def word_occurences(self):
        """
        Count the occurences of every word in the cleaned document.

        # Returns

        (dict<str, int>): A dictionary whose keys are the cleaned words of the
        document and the values are the number of times each word occurs. Every
        value is at least one, so every key occurs in the document.
        """
        bins = {}
        s = self.article_clean_word_sentences()
        flat = functools.reduce(operator.iconcat, s, [])
        for word in flat:
            if word not in bins:
                bins[word] = 1
            else:
                bins[word] += 1
        return bins
